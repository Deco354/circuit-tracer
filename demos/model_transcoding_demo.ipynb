{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Transcoding Demo\n",
    "\n",
    "This notebook demonstrates how to load and configure a model with transcoders for circuit tracing analysis.\n",
    "\n",
    "## Overview\n",
    "\n",
    "The demo shows:\n",
    "- Loading a pre-trained model (Gemma-2-2B)\n",
    "- Loading transcoders from Hugging Face\n",
    "- Configuring the model with transcoders\n",
    "- Setting up replacement MLP layers with hooks\n",
    "- Adding skip connections for transcoder functionality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/circuit-tracer/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from typing import Callable\n",
    "from circuit_tracer.transcoder import load_transcoder_set\n",
    "from circuit_tracer.transcoder.single_layer_transcoder import SingleLayerTranscoder, TranscoderSettings\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from collections import OrderedDict\n",
    "from transformer_lens import HookedTransformer\n",
    "from transformer_lens.hook_points import HookPoint\n",
    "\n",
    "# Note: We'll define ReplacementMLP and ReplacementUnembed classes in this notebook\n",
    "# instead of importing from circuit_tracer.replacement_model to avoid conflicts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Model\n",
    "\n",
    "Load a pre-trained Gemma-2-2B model using TransformerLens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 3/3 [00:00<00:00, 65.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model google/gemma-2-2b into HookedTransformer\n",
      "Model loaded on device: cuda\n",
      "Model has 26 layers\n"
     ]
    }
   ],
   "source": [
    "# Load the model\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"mps\"\n",
    "model = HookedTransformer.from_pretrained(\n",
    "    \"google/gemma-2-2b\", \n",
    "    fold_ln=False, \n",
    "    center_writing_weights=False, \n",
    "    center_unembed=False, \n",
    "    device=device\n",
    ")\n",
    "\n",
    "print(f\"Model loaded on device: {device}\")\n",
    "print(f\"Model has {model.cfg.n_layers} layers\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Transcoders\n",
    "\n",
    "Load the transcoders from Hugging Face for the Gemma model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching 26 files: 100%|██████████| 26/26 [00:00<00:00, 161.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcoders:\n",
      "dict_keys([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25])\n",
      "\n",
      "Transcoders module:\n",
      "ModuleList(\n",
      "  (0): SingleLayerTranscoder(\n",
      "    (activation_function): JumpReLU(\n",
      "      threshold=Parameter containing:\n",
      "      tensor(0.5677, device='cuda:0', requires_grad=True), bandwidth=0.1\n",
      "    )\n",
      "  )\n",
      "  (1): SingleLayerTranscoder(\n",
      "    (activation_function): JumpReLU(\n",
      "      threshold=Parameter containing:\n",
      "      tensor(0.7348, device='cuda:0', requires_grad=True), bandwidth=0.1\n",
      "    )\n",
      "  )\n",
      "  (2): SingleLayerTranscoder(\n",
      "    (activation_function): JumpReLU(\n",
      "      threshold=Parameter containing:\n",
      "      tensor(0.5816, device='cuda:0', requires_grad=True), bandwidth=0.1\n",
      "    )\n",
      "  )\n",
      "  (3): SingleLayerTranscoder(\n",
      "    (activation_function): JumpReLU(\n",
      "      threshold=Parameter containing:\n",
      "      tensor(0.7975, device='cuda:0', requires_grad=True), bandwidth=0.1\n",
      "    )\n",
      "  )\n",
      "  (4): SingleLayerTranscoder(\n",
      "    (activation_function): JumpReLU(\n",
      "      threshold=Parameter containing:\n",
      "      tensor(0.8033, device='cuda:0', requires_grad=True), bandwidth=0.1\n",
      "    )\n",
      "  )\n",
      "  (5): SingleLayerTranscoder(\n",
      "    (activation_function): JumpReLU(\n",
      "      threshold=Parameter containing:\n",
      "      tensor(0.7002, device='cuda:0', requires_grad=True), bandwidth=0.1\n",
      "    )\n",
      "  )\n",
      "  (6): SingleLayerTranscoder(\n",
      "    (activation_function): JumpReLU(\n",
      "      threshold=Parameter containing:\n",
      "      tensor(0.6528, device='cuda:0', requires_grad=True), bandwidth=0.1\n",
      "    )\n",
      "  )\n",
      "  (7): SingleLayerTranscoder(\n",
      "    (activation_function): JumpReLU(\n",
      "      threshold=Parameter containing:\n",
      "      tensor(0.9040, device='cuda:0', requires_grad=True), bandwidth=0.1\n",
      "    )\n",
      "  )\n",
      "  (8): SingleLayerTranscoder(\n",
      "    (activation_function): JumpReLU(\n",
      "      threshold=Parameter containing:\n",
      "      tensor(1.2899, device='cuda:0', requires_grad=True), bandwidth=0.1\n",
      "    )\n",
      "  )\n",
      "  (9): SingleLayerTranscoder(\n",
      "    (activation_function): JumpReLU(\n",
      "      threshold=Parameter containing:\n",
      "      tensor(1.2131, device='cuda:0', requires_grad=True), bandwidth=0.1\n",
      "    )\n",
      "  )\n",
      "  (10): SingleLayerTranscoder(\n",
      "    (activation_function): JumpReLU(\n",
      "      threshold=Parameter containing:\n",
      "      tensor(1.1184, device='cuda:0', requires_grad=True), bandwidth=0.1\n",
      "    )\n",
      "  )\n",
      "  (11): SingleLayerTranscoder(\n",
      "    (activation_function): JumpReLU(\n",
      "      threshold=Parameter containing:\n",
      "      tensor(5.7256, device='cuda:0', requires_grad=True), bandwidth=0.1\n",
      "    )\n",
      "  )\n",
      "  (12): SingleLayerTranscoder(\n",
      "    (activation_function): JumpReLU(\n",
      "      threshold=Parameter containing:\n",
      "      tensor(5.6519, device='cuda:0', requires_grad=True), bandwidth=0.1\n",
      "    )\n",
      "  )\n",
      "  (13): SingleLayerTranscoder(\n",
      "    (activation_function): JumpReLU(\n",
      "      threshold=Parameter containing:\n",
      "      tensor(5.5378, device='cuda:0', requires_grad=True), bandwidth=0.1\n",
      "    )\n",
      "  )\n",
      "  (14): SingleLayerTranscoder(\n",
      "    (activation_function): JumpReLU(\n",
      "      threshold=Parameter containing:\n",
      "      tensor(6.0921, device='cuda:0', requires_grad=True), bandwidth=0.1\n",
      "    )\n",
      "  )\n",
      "  (15): SingleLayerTranscoder(\n",
      "    (activation_function): JumpReLU(\n",
      "      threshold=Parameter containing:\n",
      "      tensor(6.6088, device='cuda:0', requires_grad=True), bandwidth=0.1\n",
      "    )\n",
      "  )\n",
      "  (16): SingleLayerTranscoder(\n",
      "    (activation_function): JumpReLU(\n",
      "      threshold=Parameter containing:\n",
      "      tensor(5.9014, device='cuda:0', requires_grad=True), bandwidth=0.1\n",
      "    )\n",
      "  )\n",
      "  (17): SingleLayerTranscoder(\n",
      "    (activation_function): JumpReLU(\n",
      "      threshold=Parameter containing:\n",
      "      tensor(6.6579, device='cuda:0', requires_grad=True), bandwidth=0.1\n",
      "    )\n",
      "  )\n",
      "  (18): SingleLayerTranscoder(\n",
      "    (activation_function): JumpReLU(\n",
      "      threshold=Parameter containing:\n",
      "      tensor(5.9814, device='cuda:0', requires_grad=True), bandwidth=0.1\n",
      "    )\n",
      "  )\n",
      "  (19): SingleLayerTranscoder(\n",
      "    (activation_function): JumpReLU(\n",
      "      threshold=Parameter containing:\n",
      "      tensor(6.8028, device='cuda:0', requires_grad=True), bandwidth=0.1\n",
      "    )\n",
      "  )\n",
      "  (20): SingleLayerTranscoder(\n",
      "    (activation_function): JumpReLU(\n",
      "      threshold=Parameter containing:\n",
      "      tensor(6.6625, device='cuda:0', requires_grad=True), bandwidth=0.1\n",
      "    )\n",
      "  )\n",
      "  (21): SingleLayerTranscoder(\n",
      "    (activation_function): JumpReLU(\n",
      "      threshold=Parameter containing:\n",
      "      tensor(7.6979, device='cuda:0', requires_grad=True), bandwidth=0.1\n",
      "    )\n",
      "  )\n",
      "  (22): SingleLayerTranscoder(\n",
      "    (activation_function): JumpReLU(\n",
      "      threshold=Parameter containing:\n",
      "      tensor(6.5800, device='cuda:0', requires_grad=True), bandwidth=0.1\n",
      "    )\n",
      "  )\n",
      "  (23): SingleLayerTranscoder(\n",
      "    (activation_function): JumpReLU(\n",
      "      threshold=Parameter containing:\n",
      "      tensor(6.0718, device='cuda:0', requires_grad=True), bandwidth=0.1\n",
      "    )\n",
      "  )\n",
      "  (24): SingleLayerTranscoder(\n",
      "    (activation_function): JumpReLU(\n",
      "      threshold=Parameter containing:\n",
      "      tensor(6.2845, device='cuda:0', requires_grad=True), bandwidth=0.1\n",
      "    )\n",
      "  )\n",
      "  (25): SingleLayerTranscoder(\n",
      "    (activation_function): JumpReLU(\n",
      "      threshold=Parameter containing:\n",
      "      tensor(6.1343, device='cuda:0', requires_grad=True), bandwidth=0.1\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Load the transcoders from hugging face\n",
    "transcoder_settings = load_transcoder_set(\"gemma\")\n",
    "transcoders: OrderedDict[int, SingleLayerTranscoder] = transcoder_settings.transcoders\n",
    "feature_input_hook: str = transcoder_settings.feature_input_hook\n",
    "feature_output_hook: str = transcoder_settings.feature_output_hook\n",
    "scan: str | list[str] = transcoder_settings.scan\n",
    "cache = {}\n",
    "\n",
    "print(\"Transcoders:\")\n",
    "print(transcoders.keys())\n",
    "\n",
    "for transcoder in transcoders.values():\n",
    "    transcoder.to(device)\n",
    "    \n",
    "transcoders_module = nn.ModuleList([transcoders[i] for i in range(model.cfg.n_layers)])\n",
    "print(\"\\nTranscoders module:\")\n",
    "print(transcoders_module)\n",
    "\n",
    "# Add transcoders to the model\n",
    "model.add_module(\"transcoders\", transcoders_module)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Replacement Classes\n",
    "\n",
    "Define the ReplacementMLP and ReplacementUnembed classes that add extra hooks to the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ReplacementMLP and ReplacementUnembed are used to add in extra hooks to the model\n",
    "# This is done by subclassing the original MLP and Unembed layers and adding in the hooks\n",
    "# The hooks are used to cache the activations and compute the skip connections\n",
    "\n",
    "class ReplacementMLP(nn.Module):\n",
    "    \"\"\"Wrapper for a TransformerLens MLP layer that adds in extra hooks\"\"\"\n",
    "\n",
    "    def __init__(self, old_mlp: nn.Module):\n",
    "        super().__init__()\n",
    "        self.old_mlp = old_mlp\n",
    "        self.hook_in = HookPoint()\n",
    "        self.hook_out = HookPoint()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.hook_in(x)\n",
    "        mlp_out = self.old_mlp(x)\n",
    "        return self.hook_out(mlp_out)\n",
    "\n",
    "\n",
    "class ReplacementUnembed(nn.Module):\n",
    "    \"\"\"Wrapper for a TransformerLens Unembed layer that adds in extra hooks\"\"\"\n",
    "\n",
    "    def __init__(self, old_unembed: nn.Module):\n",
    "        super().__init__()\n",
    "        self.old_unembed = old_unembed\n",
    "        self.hook_pre = HookPoint()\n",
    "        self.hook_post = HookPoint()\n",
    "\n",
    "    @property\n",
    "    def W_U(self):\n",
    "        return self.old_unembed.W_U\n",
    "\n",
    "    @property\n",
    "    def b_U(self):\n",
    "        return self.old_unembed.b_U\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.hook_pre(x)\n",
    "        x = self.old_unembed(x)\n",
    "        return self.hook_post(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Up Activation Caching\n",
    "\n",
    "Define a function to cache activations during forward passes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Replace MLP & Unembed Layers with Hook wrappers\n",
    "\n",
    "Replace the original MLP layers with our ReplacementMLP wrapper that includes additional hooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "All MLP layers have been replaced with ReplacementMLP wrappers\n"
     ]
    }
   ],
   "source": [
    "# Replace MLP layers with ReplacementMLP\n",
    "for transformer_block in model.blocks:\n",
    "    transformer_block.mlp = ReplacementMLP(transformer_block.mlp)\n",
    "model.unembed = ReplacementUnembed(model.unembed)\n",
    "    \n",
    "print(\"\\nAll MLP layers have been replaced with ReplacementMLP wrappers\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect model to SAE transcoder using hooks\n",
    "\n",
    "Add hooks to cache input and output activations to MLP blocks for each layer. Add skip hooks for each layer where they're present."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added hooks to 26 layers\n"
     ]
    }
   ],
   "source": [
    "def cache_activations(acts, hook):\n",
    "    \"\"\"Cache activations for later use\"\"\"\n",
    "    cache[\"acts\"] = acts\n",
    "\n",
    "# Add skip connections\n",
    "for layer, transcoder in enumerate(transcoders.values()):\n",
    "    transformer_block = model.blocks[layer]\n",
    "    mlp_block = getattr(transformer_block, \"mlp\")\n",
    "    \n",
    "    input_hookpoint: HookPoint = getattr(mlp_block, \"hook_in\")\n",
    "    input_hookpoint.add_hook(cache_activations, is_permanent=True)\n",
    "    \n",
    "    output_hookpoint: HookPoint = getattr(mlp_block, \"hook_out\")\n",
    "    output_hookpoint.add_hook(cache_activations, is_permanent=True)\n",
    "    \n",
    "    # Add skip connection\n",
    "    if transcoder.W_skip is not None:\n",
    "        skip = transcoder.compute_skip(cache[\"acts\"])\n",
    "        mlp_block.add_hook(skip, is_permanent=True)\n",
    "        \n",
    "print(f\"Added hooks to {len(transcoders)} layers\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure Gradient Flow\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Disable gradient on all parameters\n",
    "This ensures that the pre-trained model parameters remain frozen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detach gradients\n",
    "Our parameters won't update during back prop as we've disabled `require_grad` however we still need the gradients to calculate our feature contributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def enable_gradient(acts, hook):\n",
    "    acts.requires_grad = True\n",
    "    return acts\n",
    "\n",
    "def stop_gradient(acts, hook):\n",
    "    return acts.detach()\n",
    "\n",
    "model.hook_embed.add_hook(enable_gradient, is_permanent=True)\n",
    "\n",
    "for block in model.blocks:\n",
    "    block.attn.hook_pattern.add_hook(stop_gradient, is_permanent=True)\n",
    "    block.ln1.hook_scale.add_hook(stop_gradient, is_permanent=True)\n",
    "    block.ln2.hook_scale.add_hook(stop_gradient, is_permanent=True)\n",
    "    if hasattr(block, \"ln1_post\"):\n",
    "        block.ln1_post.hook_scale.add_hook(stop_gradient, is_permanent=True)\n",
    "    if hasattr(block, \"ln2_post\"):\n",
    "        block.ln2_post.hook_scale.add_hook(stop_gradient, is_permanent=True)\n",
    "    model.ln_final.hook_scale.add_hook(stop_gradient, is_permanent=True)\n",
    "\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Configuration Summary\n",
    "\n",
    "Let's check the final configuration of our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model configuration summary:\n",
      "- Device: cuda\n",
      "- Number of layers: 26\n",
      "- Number of transcoders: 26\n",
      "- Feature input hook: ln2.hook_normalized\n",
      "- Feature output hook: hook_mlp_out\n",
      "- Scan: gemma-2-2b\n",
      "- Model has transcoders module: True\n",
      "- All MLPs replaced with ReplacementMLP: True\n"
     ]
    }
   ],
   "source": [
    "print(\"Model configuration summary:\")\n",
    "print(f\"- Device: {device}\")\n",
    "print(f\"- Number of layers: {model.cfg.n_layers}\")\n",
    "print(f\"- Number of transcoders: {len(transcoders)}\")\n",
    "print(f\"- Feature input hook: {feature_input_hook}\")\n",
    "print(f\"- Feature output hook: {feature_output_hook}\")\n",
    "print(f\"- Model: {scan}\")\n",
    "\n",
    "# Check if MLPs have been replaced\n",
    "mlp_replaced = all(isinstance(block.mlp, ReplacementMLP) for block in model.blocks)\n",
    "print(f\"- All MLPs replaced with ReplacementMLP: {mlp_replaced}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the Model\n",
    "\n",
    "Let's test that our model works correctly with a simple forward pass."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing model with input: 'Hello, world!'\n",
      "✓ Model forward pass successful!\n",
      "  Output shape: torch.Size([1, 5, 256000])\n",
      "  Output dtype: torch.float32\n"
     ]
    }
   ],
   "source": [
    "# Test the model with a simple input\n",
    "test_input = \"Hello, world!\"\n",
    "print(f\"Testing model with input: '{test_input}'\")\n",
    "\n",
    "try:\n",
    "    with torch.no_grad():\n",
    "        logits = model(test_input)\n",
    "    print(f\"✓ Model forward pass successful!\")\n",
    "    print(f\"  Output shape: {logits.shape}\")\n",
    "    print(f\"  Output dtype: {logits.dtype}\")\n",
    "except Exception as e:\n",
    "    print(f\"✗ Model forward pass failed: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "The model is now configured with transcoders and ready for circuit tracing analysis. You can:\n",
    "\n",
    "1. **Get activations**: Use the model to extract transcoder activations for specific inputs\n",
    "2. **Perform interventions**: Modify specific features and observe their effects\n",
    "3. **Analyze circuits**: Study how different features contribute to model behavior\n",
    "4. **Visualize results**: Create plots and visualizations of the circuit analysis\n",
    "\n",
    "For more advanced usage, refer to the other demo notebooks in this directory."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "circuit-tracer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
